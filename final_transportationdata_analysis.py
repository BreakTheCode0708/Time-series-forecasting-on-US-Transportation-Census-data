# -*- coding: utf-8 -*-
"""Final_TransportationData Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dLPA2L87cgIAMF0qgQQRhZEQgeLGs6xR
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#to ignore warnings
import warnings
warnings.filterwarnings('ignore')

from pydrive.auth import GoogleAuth

from pydrive.drive import GoogleDrive

from google.colab import auth

from oauth2client.client import GoogleCredentials

auth.authenticate_user()

gauth = GoogleAuth()

gauth.credentials = GoogleCredentials.get_application_default()

drive = GoogleDrive(gauth)

#https://docs.google.com/spreadsheets/d/1XTLY0Eia01ZHwEucOs9LRYnfgNDVRds-/edit#gid=611352686
fileDownloaded = drive.CreateFile({'id':'1XTLY0Eia01ZHwEucOs9LRYnfgNDVRds-'})

#https://docs.google.com/spreadsheets/d/1unc9dXrrUoPclVzgDJY19eAIr_SZUvYC/edit#gid=355141095
file2=drive.CreateFile({'id':'1unc9dXrrUoPclVzgDJY19eAIr_SZUvYC'})

file2.GetContentFile('AugustDB2002-2010.xlsx')

gdf=pd.read_excel(io='AugustDB2002-2010.xlsx',sheet_name='VRM')

gdf.head()

fileDownloaded.GetContentFile('August 2022 Raw Database.xlsx')

import pandas as pd

df = pd.read_excel(io='August 2022 Raw Database.xlsx',sheet_name='UPT')
df2=pd.read_excel(io='August 2022 Raw Database.xlsx',sheet_name='UPT')

df2.head()

"""EDA"""

df2.head()

summary_stats = df2.describe()
print(summary_stats)

plt.figure(figsize=(8, 6))
df['Active'].value_counts().plot(kind='bar')
plt.xlabel('Active')
plt.ylabel('Count')
plt.title('Distribution of Active Status')
plt.show()

plt.figure(figsize=(8, 6))
df['Reporter Type'].value_counts().plot(kind='bar')
plt.xlabel('Reporter Type')
plt.ylabel('Count')
plt.title('Distribution of Reporter Types')
plt.show()

# Histogram of Modes
plt.figure(figsize=(8, 6))
df['Modes'].hist()
plt.xlabel('Modes')
plt.ylabel('Frequency')
plt.title('Distribution of Modes')
plt.show()

plt.figure(figsize=(8, 6))
df['TOS'].hist()
plt.xlabel('TOS')
plt.ylabel('Frequency')
plt.title('Distribution of TOS')
plt.show()

# Line plot of monthly data for a specific agency
agency_data = df2[df2['Agency'] == 'King County Department of Metro Transit']
agency_data = agency_data.iloc[:, 9:]  # Select only the columns representing monthly data

plt.figure(figsize=(20, 6))
for column in agency_data.columns:
    plt.plot(agency_data.index, agency_data[column], label=column)
plt.xlabel('Year')
plt.ylabel('Value')
plt.title('Monthly Data Trends for King County Department of Metro Transit')
plt.legend()
plt.show()

cat_cols=df.select_dtypes(include=['object']).columns
num_cols = df.select_dtypes(include=np.number).columns.tolist()
print("Categorical Variables:")
print(cat_cols)
print("Numerical Variables:")
print(num_cols)

for col in num_cols:
    print(col)
    print('Skew :', round(df2[col].skew(), 2))
    plt.figure(figsize = (15, 4))
    plt.subplot(1, 2, 1)
    df[col].hist(grid=False)
    plt.ylabel('count')
    plt.subplot(1, 2, 2)
    sns.boxplot(x=df[col])
    plt.show()

"""RESHAPING THE DATASET"""

# Specify the columns to keep
columns_to_keep = ['UZA Name', 'Months','JAN02']

# Remove all columns except the specified ones
diff = df2.drop(df2.columns.difference(columns_to_keep), axis=1)

diff.head()

diff = diff.rename(columns={'JAN02': 'Values'})

df.tail()

# Specify the columns to keep
columns_to_keep = ['UZA Name', 'Month']

# Remove all columns except the specified ones
dif = df.drop(df.columns.difference(columns_to_keep), axis=1)

dif.head()

# Transpose a specific part of the DataFrame
df_part_transposed = df.loc[:, 'JAN02':'AUG 22'].transpose()

df_part_transposed.head()

df_part_transposed = df_part_transposed.join(dif)

df_part_transposed['UZA Name'] = df['UZA Name']

df_part_transposed['Month'] = df['Month']

df_part_transposed.head()

#df_part_transposed.columns = ['JAN02','FEB02', 'MAR02', 'APR02', 'MAY02', 'JUN02', 'JUL02', 'AUG02', 'SEP02', 'OCT02', 'NOV02', 'DEC02', 'JAN03', 'FEB03', 'MAR03', 'APR03', 'MAY03', 'JUN03', 'JUL03', 'AUG03', 'SEP03', 'OCT03', 'NOV03', 'DEC03', 'JAN04', 'FEB04', 'MAR04', 'APR04', 'MAY04', 'JUN04', 'JUL04', 'AUG04', 'SEP04', 'OCT04', 'NOV04', 'DEC04', 'JAN05', 'FEB05', 'MAR05', 'APR05', 'MAY05', 'JUN05', 'JUL05', 'AUG05', 'SEP05', 'OCT05', 'NOV05', 'DEC05','a','b','c','d','e','f','g','h','i','j','k','l','m','UZA Name','Month']

# Specify the columns to keep
columns_to_keep = ['JAN02', 'UZA Name','Month']

# Remove all columns except the specified ones
df_filtered = df_part_transposed.drop(df_part_transposed.columns.difference(columns_to_keep), axis=1)

df_filtered.head()

df_filtered = df_filtered.rename(columns={'JAN02': 'Values'})

print(df)

"""simple exponential smoothening"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing, Holt
from pylab import rcParams

import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import mean_squared_error as mse
from math import sqrt

diff.head()

diff.info

diff.dropna(inplace = True)

diff['Values'].plot(figsize=(15,5))

diff['Values'].describe()

data = diff['Values']

fit1 = SimpleExpSmoothing(data).fit(smoothing_level = 0.2,optimized = False)
fit2 = SimpleExpSmoothing(data).fit(smoothing_level = 0.8,optimized = False)

diff['Values'].plot(figsize=(15,5),marker='o',color='black')
fit1.fittedvalues.plot(figsize=(15,5),marker='+',color='red')
fit2.fittedvalues.plot(figsize=(15,5),marker='o',color='blue')

import plotly.graph_objects as go
import pandas as pd
from statsmodels.tsa.holtwinters import SimpleExpSmoothing

# Split train and test
train = diff.iloc[:-int(len(diff) * 0.2)]
test = diff.iloc[-int(len(diff) * 0.2):]

def plot_func(forecast: list[float], title: str) -> None:
    """Function to plot the forecasts."""
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=train['UZA Name'], y=train['Values'], name='Train'))
    fig.add_trace(go.Scatter(x=test['UZA Name'], y=test['Values'], name='Test'))
    fig.add_trace(go.Scatter(x=test['UZA Name'], y=forecast, name='Forecast'))
    fig.update_layout(template="simple_white", font=dict(size=18), title_text=title,
                      width=650, title_x=0.5, height=400, xaxis_title='UZA Name',
                      yaxis_title='forcasted values')

# Fit model and get forecasts
model = SimpleExpSmoothing(train['Values']).fit(optimized=True)
forecasts = model.forecast(len(test))

# Plot the forecasts
plot_func(forecasts, 'Simple Exponential Smoothing')

model.summary()

"""prophet Modelling




"""

from prophet import Prophet

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt

# %matplotlib inline

plt.rcParams['figure.figsize']=(20,10)
plt.style.use('ggplot')

gdf

gdf.dropna(inplace=True)

gdf['Values1'] = gdf['Values1'].astype(int)

# Rename the columns to 'ds' and 'y' as required by Prophet
gdf = gdf.rename(columns={'Months': 'ds', 'Values1': 'y'})

# Create and fit the Prophet model
model = Prophet()
model.fit(gdf)

# Create and fit the Prophet model
model = Prophet()
model.fit(gdf)

# Generate future dates for prediction
future_dates = model.make_future_dataframe(periods=12, freq='M')

# Make predictions
forecast = model.predict(future_dates)

forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

fig1 = model.plot(forecast)

fig2 = model.plot_components(forecast)

from prophet.plot import plot_plotly, plot_components_plotly

plot_plotly(model, forecast)

"""test train"""

forecast.head()

gdf.head()

model

# train = forecast[(forecast['ds'] >= '2002-01') & (forecast['ds'] <= '2005-12')]
# test =  forecast[(forecast['ds'] > '2005-12')]

train = gdf[(gdf['ds'] >= '2002-01') & (gdf['ds'] <= '2005-12')]
test =  gdf[(gdf['ds'] > '2005-12')]

train.shape

train.head()

test.shape

m = Prophet(interval_width = 0.95)

m.fit(train)

future = m.make_future_dataframe(freq='M',periods=11)
future.tail(12)

forecast1 = m.predict(future)
forecast1[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(10)

pd.concat([gdf.set_index('ds')['y'],forecast1.set_index('ds')['yhat']],axis=1).plot(figsize = (15,5))

m.plot(forecast1,figsize=(15,5))

plot_plotly(m, forecast1)

"""Simple exponenetial smoothening"""

# Commented out IPython magic to ensure Python compatibility.
 import pandas as pd
 import numpy as np
 from sklearn import metrics
 import matplotlib.pyplot as plt
#  %matplotlib inline
 from sklearn.model_selection import ParameterGrid
 from statsmodels.tsa.api import SimpleExpSmoothing
 from statsmodels.tsa.api import Holt
 from statsmodels.tsa.api import ExponentialSmoothing

gdf.head()

close = gdf['Values2']
testclose = close.iloc[-30:]
trainclose = close.iloc[:-30]

def MAPE(y_true, y_pred):
     y_true, y_pred = np.array(y_true), np.array(y_pred)
     return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def timeseries_evaluation_metrics(y_true, y_pred):
   print('Evaluation metric results: ')
   print(f'MSE value : {metrics.mean_squared_error(y_true, y_pred)}')
   print(f'MAE value : {metrics.mean_absolute_error(y_true, y_pred)}')
   print(f'RMSE value : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')
   print(f'MAPE value : {mean_absolute_percentage_error(y_true, y_pred)}')
   print(f'R2 score : {metrics.r2_score(y_true, y_pred)}',end='\n\n')

temp_df = pd.DataFrame()
 for i in [0 , 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90,1]:
     print(f'Fitting for smoothing level= {i}')
     fit_v = SimpleExpSmoothing(np.asarray(trainclose)).fit(i)
     fcst_pred_v= fit_v.forecast(len(testclose))
     timeseries_evaluation_metrics(testclose, fcst_pred_v)

temp_df = pd.DataFrame()
 for i in [0 , 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90,1]:
     fit_v = SimpleExpSmoothing(np.asarray(trainclose)).fit(i)
     fcst_pred_v= fit_v.forecast(len(testclose))
     rmse = np.sqrt(metrics.mean_squared_error(testclose, fcst_pred_v))
     df3 = {'smoothing parameter':i, 'RMSE': rmse}
     temp_df = temp_df.append(df3, ignore_index=True)
 temp_df.sort_values(by=['RMSE'])

SES = SimpleExpSmoothing(np.asarray(trainclose))
 fit_SES_auto = SES.fit(optimized= True, use_brute = True)
 fcst_auto_pred = fit_SES_auto.forecast(len(testclose))
 timeseries_evaluation_metrics(testclose, fcst_auto_pred)

fit_SES_auto.summary()

df_fcst_auto_pred = pd.DataFrame(fcst_auto_pred, columns=['Close_auto_search'])
 df_fcst_auto_pred["new_index"] = range(len(trainclose), len(close))
 df_fcst_auto_pred = df_fcst_auto_pred.set_index("new_index")

plt.rcParams["figure.figsize"] = [16,9]
 plt.plot(trainclose, label='Train')
 plt.plot(testclose, label='Test')
 plt.plot(df_fcst_auto_pred, label='Simple Exponential Smoothing using optimized=True')
 plt.legend(loc='best')
 plt.show()

"""Holt Winter's Method"""

gdf.head()

gdf.dropna(inplace = True)

gdf ['Values2'].fillna(value= gdf ['Values2'].mean(), inplace=True)

import pandas as pd
from matplotlib import pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import SimpleExpSmoothing
from statsmodels.tsa.holtwinters import ExponentialSmoothing

gdf[['Values2']].plot(title='Transoptation Data')

gdf.sort_index(inplace=True) # sort the data as per the index
# Decompose the data frame to get the trend, seasonality and noise
decompose_result = seasonal_decompose(gdf['Values2'],period=10)
decompose_result.plot()
plt.show()

# Set the value of Alpha and define x as the time period
x = 12
alpha = 1/(2*x)
# Single exponential smoothing of the visitors data set
gdf['ds'] = SimpleExpSmoothing(gdf['Values2']).fit(smoothing_level=alpha,optimized=False,use_brute=True).fittedvalues
gdf[['Values2','ds']].plot(title='Holt Winters Single Exponential Smoothening graph')



"""LIGHT GBM-Model"""

pip install lightgbm

from lightgbm import LGBMRegressor
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import os
from tqdm import tqdm
import random
import seaborn as sns
import math
import warnings

pip install sklearn

from sklearn.model_selection import train_test_split

X = gdf.drop(['Values3','UZA Name'], axis=1)
y = gdf['Values3']
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.01, random_state=42, shuffle=False)

model = LGBMRegressor()
model.get_params()

model.fit(X_train, y_train,eval_set=[(X_valid, y_valid)],
          verbose=50,
          eval_metric='rmse',
          early_stopping_rounds=20)

model = LGBMRegressor(
        objective="regression",
        metric="l2",
        boosting_type="gbdt",
        n_estimators=1400,
        num_leaves=100,
        max_depth=10,
        learning_rate=0.05,
        subsample=0.8)

model.fit(X_train,y_train)

def plotImp(model, X , num = 20, fig_size = (40, 20)):
    feature_imp = pd.DataFrame({'Value':model.feature_importances_,'Feature':X.columns})
    plt.figure(figsize=fig_size)
    sns.set(font_scale = 5)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
                                                        ascending=False)[0:num])
    plt.title('LightGBM Features')
    plt.tight_layout()
    plt.savefig('lgbm_importances-01.png')
    plt.show()

plotImp(model, X_valid)